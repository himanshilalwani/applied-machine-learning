{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efb16b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, recall_score,precision_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac6372b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=1000, centers=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2a2eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler_fit =scaler.fit(X)\n",
    "X_scaled = scaler_fit.transform(X)\n",
    "\n",
    "# Relabel the y-targets\n",
    "y = np.where(y == 0, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8611183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ebe353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the bias\n",
    "X_train = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "X_test =  np.c_[np.ones((X_test.shape[0], 1)), X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4484188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for svm\n",
    "def loss_function(X, y, C, theta):\n",
    "    m = X.shape[0]\n",
    "    loss = 0\n",
    "    reg_term = (1/2)*(theta.T.dot(theta))\n",
    "    for i in range(m):\n",
    "        loss += reg_term + (C * max(0, 1-(y[i]*(theta.dot(X[i])))))\n",
    "    \n",
    "    loss = loss / m\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7a8832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient function for svm\n",
    "def gradient(X_i, y_i, theta, C, N):\n",
    "    if max(0, 1-(y_i*(X_i.dot(theta)))) == 0:\n",
    "        return theta / N\n",
    "    return (theta - (C*y_i*X_i)) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6d400",
   "metadata": {},
   "source": [
    "##### Decision Function\n",
    "Trained weight vector multiplied by the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b9c471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function for svm\n",
    "def predict(theta, X):\n",
    "    pred = X.dot(theta)\n",
    "    return np.where(pred <= 0, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "314d4dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating precision, recall, f_score, accuracy\n",
    "def scores(y, y_pred):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1 and y_pred[i] == 1:\n",
    "            tp += 1\n",
    "        elif y[i] == 1 and y_pred[i] == -1:\n",
    "            fn += 1\n",
    "        elif y[i] == -1 and y_pred[i] == 1:\n",
    "            fp += 1\n",
    "        elif y[i] == -1 and y_pred[i] == -1:\n",
    "            tn += 1\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f_score = 2*precision*recall/(precision+recall)\n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn)\n",
    "    return precision, recall, f_score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d2d74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0, t1 = 5,50\n",
    "n_iterations = 500\n",
    "C = 100\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "# calculating the coefficient vector\n",
    "def weight(X_train, y_train, n_iterations, C):\n",
    "    m = X_train.shape[0]\n",
    "    n = X_train.shape[1]\n",
    "    theta = np.random.rand(n) # random initialisation\n",
    "    random_idx = []\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(1, n_iterations):\n",
    "        for i in range(m):\n",
    "            random_index = np.random.randint(m)\n",
    "            while random_index in random_idx: # getting unique random index\n",
    "                random_index = np.random.randint(m)\n",
    "            xi = X_train[random_index]\n",
    "            yi = y_train[random_index]\n",
    "            gi = gradient(xi, yi, theta, C, m)\n",
    "            eta = learning_schedule(epoch * m + i)\n",
    "            theta = theta - eta * gi\n",
    "        loss_list.append(loss_function(X_train, y_train, C, theta))\n",
    "    return theta, loss_list\n",
    "\n",
    "theta, loss_list = weight(X_train, y_train, n_iterations, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45c52df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9534883720930233 0.9534883720930233 0.9534883720930233 0.952\n"
     ]
    }
   ],
   "source": [
    "# predicting on the testing set and evaluating the predictions\n",
    "y_pred = predict(theta, X_test)\n",
    "precision, recall, f_score, accuracy = scores(y_test, y_pred)\n",
    "print(precision, recall, f_score, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ffb7efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9514824797843666 0.9514824797843666 0.9514824797843666 0.952\n"
     ]
    }
   ],
   "source": [
    "# predicting on the training set and evaluating the predictions\n",
    "y_pred_train = predict(theta, X_train)\n",
    "precision_t, recall_t, f_score_t, accuracy_t = scores(y_train, y_pred_train)\n",
    "print(precision_t, recall_t, f_score_t, accuracy_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4c5390a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[115   6]\n",
      " [  6 123]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for testing predictions\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2568cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[361  18]\n",
      " [ 18 353]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix for training predictions\n",
    "confusionMatrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "print(confusionMatrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "efc7d2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Distance:  0.003603874975510126\n",
      "Index of the instance with minimum distance:  692\n",
      "Instance with the minimum distance:  [1.         0.57447184 0.25745982]\n"
     ]
    }
   ],
   "source": [
    "# calculating the distances of each point in the training dataset from the decision boundary\n",
    "theta_norm = np.linalg.norm(theta)\n",
    "distances = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    d = abs((X_train[i].dot(theta)) / theta_norm)\n",
    "    distances.append(d)\n",
    "    \n",
    "min_distance = min(distances)\n",
    "min_idx = distances.index(min_distance)\n",
    "\n",
    "print(\"Minimum Distance: \", min_distance)\n",
    "print(\"Index of the instance with minimum distance: \", min_idx)\n",
    "print(\"Instance with the minimum distance: \", X_train[min_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b787b0",
   "metadata": {},
   "source": [
    "Which of the training examples are closest to the decision boundary in the SVM\n",
    "primal problem?\n",
    "\n",
    "Minimum Distance:  0.003603874975510126\n",
    "\n",
    "Index of the instance with minimum distance:  692\n",
    "\n",
    "Instance with the minimum distance:  [1.         0.57447184 0.25745982]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "880b550c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Precision:  0.9592875318066157\n",
      "Traning Recall:  0.9308641975308642\n",
      "Traning F score:  0.9448621553884712\n",
      "Traning Accuracy:  0.945\n",
      "Traning Confusion Matrix:  [[379  16]\n",
      " [ 28 377]]\n",
      "----------------------------------------\n",
      "Testing Precision:  0.9770114942528736\n",
      "Testing Recall:  0.8947368421052632\n",
      "Testing F score:  0.9340659340659342\n",
      "Testing Accuracy:  0.94\n",
      "Testing Confusion Matrix:  [[103   2]\n",
      " [ 10  85]]\n",
      "========================================\n",
      "========================================\n",
      "Training Precision:  0.972972972972973\n",
      "Traning Recall:  0.9113924050632911\n",
      "Traning F score:  0.9411764705882353\n",
      "Traning Accuracy:  0.94375\n",
      "Traning Confusion Matrix:  [[395  10]\n",
      " [ 35 360]]\n",
      "----------------------------------------\n",
      "Testing Precision:  0.9504950495049505\n",
      "Testing Recall:  0.9142857142857143\n",
      "Testing F score:  0.9320388349514563\n",
      "Testing Accuracy:  0.93\n",
      "Testing Confusion Matrix:  [[90  5]\n",
      " [ 9 96]]\n",
      "========================================\n",
      "========================================\n",
      "Training Precision:  0.9699453551912568\n",
      "Traning Recall:  0.9033078880407125\n",
      "Traning F score:  0.9354413702239789\n",
      "Traning Accuracy:  0.93875\n",
      "Traning Confusion Matrix:  [[396  11]\n",
      " [ 38 355]]\n",
      "----------------------------------------\n",
      "Testing Precision:  0.9636363636363636\n",
      "Testing Recall:  0.9906542056074766\n",
      "Testing F score:  0.9769585253456221\n",
      "Testing Accuracy:  0.975\n",
      "Testing Confusion Matrix:  [[ 89   4]\n",
      " [  1 106]]\n",
      "========================================\n",
      "========================================\n",
      "Training Precision:  0.9667519181585678\n",
      "Traning Recall:  0.9219512195121952\n",
      "Traning F score:  0.9438202247191011\n",
      "Traning Accuracy:  0.94375\n",
      "Traning Confusion Matrix:  [[377  13]\n",
      " [ 32 378]]\n",
      "----------------------------------------\n",
      "Testing Precision:  0.9761904761904762\n",
      "Testing Recall:  0.9111111111111111\n",
      "Testing F score:  0.9425287356321839\n",
      "Testing Accuracy:  0.95\n",
      "Testing Confusion Matrix:  [[108   2]\n",
      " [  8  82]]\n",
      "========================================\n",
      "========================================\n",
      "Training Precision:  0.9708994708994709\n",
      "Traning Recall:  0.924433249370277\n",
      "Traning F score:  0.9470967741935483\n",
      "Traning Accuracy:  0.94875\n",
      "Traning Confusion Matrix:  [[392  11]\n",
      " [ 30 367]]\n",
      "----------------------------------------\n",
      "Testing Precision:  0.9680851063829787\n",
      "Testing Recall:  0.883495145631068\n",
      "Testing F score:  0.9238578680203046\n",
      "Testing Accuracy:  0.925\n",
      "Testing Confusion Matrix:  [[94  3]\n",
      " [12 91]]\n",
      "========================================\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Testing the model using k fold validation\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "n_iterations = 900\n",
    "C = 20\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_scaled)):\n",
    "    X_train = X[train_index]\n",
    "    X_train = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "    y_train = y[train_index]\n",
    "    theta, loss_list = weight(X_train, y_train, n_iterations, C)\n",
    "    y_pred = predict(theta, X_train)\n",
    "    p, r, f, a = scores(y_train, y_pred)\n",
    "    print(\"Training Precision: \", p)\n",
    "    print(\"Traning Recall: \", r)\n",
    "    print(\"Traning F score: \", f)\n",
    "    print(\"Traning Accuracy: \", a)\n",
    "    confusionMatrix = confusion_matrix(y_train, y_pred)\n",
    "    print(\"Traning Confusion Matrix: \", confusionMatrix)\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "    \n",
    "    X_test = X[test_index]\n",
    "    X_test =  np.c_[np.ones((X_test.shape[0], 1)), X_test]\n",
    "    y_test = y[test_index]\n",
    "    y_pred = predict(theta, X_test)\n",
    "    p, r, f, a = scores(y_test, y_pred)\n",
    "    print(\"Testing Precision: \", p)\n",
    "    print(\"Testing Recall: \", r)\n",
    "    print(\"Testing F score: \", f)\n",
    "    print(\"Testing Accuracy: \", a)\n",
    "    confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Testing Confusion Matrix: \", confusionMatrix)\n",
    "    print(\"========================================\")\n",
    "    print(\"========================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
