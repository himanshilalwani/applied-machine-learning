{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "81G6zc9SHiLO"
      },
      "outputs": [],
      "source": [
        "# importing the required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1boQC1vImGf",
        "outputId": "e57f929a-c14e-46b5-905f-248d3a9955c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node():\n",
        "  def __init__(self, feature = None, threshold = None, left_child = None, right_child = None, leaf_value = None):\n",
        "    self.feature = feature\n",
        "    self.threshold = threshold\n",
        "    self.left_child = left_child\n",
        "    self.right_child = right_child\n",
        "    self.leaf_value = leaf_value"
      ],
      "metadata": {
        "id": "S-ILPSPIJIg3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tree():\n",
        "  # constructor\n",
        "  def __init__(self, X, n_min):\n",
        "    self.root = None\n",
        "    self.features = [feat for feat in range(X.shape[1])]\n",
        "    self.n_min = round((n_min / 100) * X.shape[0])\n",
        "\n",
        "  # build tree\n",
        "  def grow_tree(self, X, y):\n",
        "    labels = len(np.unique(y))\n",
        "    \n",
        "    # leaf conditions\n",
        "    # 1. samples less than the n_min condition\n",
        "    # 2. pure node\n",
        "    if X.shape[0] < self.n_min or labels == 1:\n",
        "      leaf_val = self.common_val(y) # finding the most common occurence\n",
        "      return Node(leaf_value = leaf_val)\n",
        "    \n",
        "    # best feature based on max info gain\n",
        "    best_feature, best_info_gain, best_thresh = self.best_feature(X, y)\n",
        "\n",
        "    left_split, left_y, right_split, right_y = self.split_func(X, y, best_feature, best_thresh)\n",
        "\n",
        "    # recursively creating sub trees\n",
        "    left_subtree = self.grow_tree(left_split, left_y)\n",
        "    right_subtree = self.grow_tree(right_split, right_y)\n",
        "    return Node(best_feature, best_thresh, left_subtree, right_subtree)\n",
        " \n",
        "  # average of adjacent vals\n",
        "  def average_func(self, feature):\n",
        "    mean_vals = np.zeros(len(feature))\n",
        "    for i in range(len(feature)-1):\n",
        "      mean_val = (feature[i] + feature[i+1]) / 2\n",
        "      mean_vals[i] = mean_val\n",
        "    return mean_vals\n",
        "\n",
        "  # common value of a feature\n",
        "  def common_val(self, y):\n",
        "      vals = np.unique(y)\n",
        "      counts = {}\n",
        "      for val in vals:\n",
        "        counts[val] = 0\n",
        "      for x in y:\n",
        "        counts[x] += 1\n",
        "      max_val = max(counts, key = lambda x: counts[x]) \n",
        "      return max_val\n",
        "    \n",
        "  # entropy of the target column\n",
        "  def entropy(self, y):\n",
        "    unique_vals, counts = np.unique(y, return_counts = True)\n",
        "    sum = 0\n",
        "    for i in range(len(unique_vals)):\n",
        "      prob_val = counts[i] / len(y)\n",
        "      sum += - prob_val * np.log2(prob_val)\n",
        "    return sum\n",
        "  \n",
        "  # split function\n",
        "  def split_func(self, X, y, feature, threshold):\n",
        "    left_split_feat = []\n",
        "    left_split_target = []\n",
        "    right_split_feat = []\n",
        "    right_split_target = []\n",
        "    for i in range(X.shape[0]):\n",
        "      if X[i, feature] < threshold:\n",
        "         left_split_feat.append(X[i, :])\n",
        "         left_split_target.append(y[i])\n",
        "      else:\n",
        "         right_split_feat.append(X[i, :])\n",
        "         right_split_target.append(y[i])\n",
        "  \n",
        "    return np.array(left_split_feat), np.array(left_split_target), np.array(right_split_feat), np.array(right_split_target)\n",
        "\n",
        "  # information gain of a feature column\n",
        "  def information_gain(self, feature_col, y, X, threshold):\n",
        "    parent_entropy = self.entropy(y)\n",
        "    left_split, left_y, right_split, right_y = self.split_func(X, y, feature_col, threshold)\n",
        "    if len(left_split) == 0 or len(right_split) == 0:\n",
        "      return 0\n",
        "    left_child_entropy = ((len(left_split) / len(y)) * self.entropy(left_y))\n",
        "    right_child_entropy = ((len(right_split) / len(y)) * self.entropy(right_y))\n",
        "    gain = parent_entropy - (left_child_entropy + right_child_entropy)\n",
        "    return gain\n",
        "  \n",
        "  # best feature based of max info gain\n",
        "  def best_feature(self, X, y):\n",
        "    n = X.shape[0] # number of samples\n",
        "    m = X.shape[1] # number of features\n",
        "    best_feature = None\n",
        "    best_info_gain = -float(\"inf\")\n",
        "    best_thresh = None\n",
        "    for feature in self.features:\n",
        "      feature_values = X[:, feature]\n",
        "      unique_feature_values = np.unique(feature_values)\n",
        "      possible_thresholds = self.average_func(unique_feature_values)\n",
        "      for threshold in possible_thresholds:\n",
        "        info_gain = self.information_gain(feature, y, X, threshold)\n",
        "        if info_gain > best_info_gain:\n",
        "          best_info_gain = info_gain\n",
        "          best_feature = feature\n",
        "          best_thresh = threshold\n",
        "\n",
        "    return best_feature, best_info_gain, best_thresh\n",
        "\n",
        "  # predict\n",
        "  def predict(self, X):\n",
        "    preds = []\n",
        "    for i in range(len(X)):\n",
        "      curr_node = self.root\n",
        "      while (curr_node.leaf_value == None):\n",
        "        if (X[i, curr_node.feature] < curr_node.threshold):\n",
        "          curr_node = curr_node.left_child\n",
        "        else:\n",
        "          curr_node = curr_node.right_child\n",
        "      preds.append(curr_node.leaf_value)\n",
        "    return preds\n",
        "  \n",
        "  # start building the tree\n",
        "  def fit(self, X, y):\n",
        "    self.root = self.grow_tree(X, y)"
      ],
      "metadata": {
        "id": "Fa7RtGugKUO8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(actual, pred):\n",
        "  correct = 0\n",
        "  for i in range(len(actual)):\n",
        "    if actual[i] == pred[i]:\n",
        "      correct += 1\n",
        "  return (correct / len(actual))"
      ],
      "metadata": {
        "id": "yE-JmbRS5TUW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test(X, y, n_min):\n",
        "  accuracy_list = [] # used to store accuracy for each fold\n",
        "  kf = KFold(n_splits=10) # 10 fold cross validation\n",
        "  for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train = X[train_index]\n",
        "    y_train = y[train_index]\n",
        "    X_test = X[test_index]\n",
        "    y_test = y[test_index]\n",
        "    decision_tree = Tree(X_train, n_min)\n",
        "    decision_tree.fit(X_train, y_train)\n",
        "    y_pred = decision_tree.predict(X_test)\n",
        "    accuracy_score = accuracy(y_test, np.array(y_pred))\n",
        "    accuracy_list.append(accuracy_score)\n",
        "  \n",
        "  accuracy_list = np.array(accuracy_list)\n",
        "  average_accuracy = np.mean(accuracy_list) # average\n",
        "  standard_dev = np.std(accuracy_list) # standard deviation\n",
        "\n",
        "  return average_accuracy, standard_dev"
      ],
      "metadata": {
        "id": "CTIYu6ab8NP_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Iris Datset**"
      ],
      "metadata": {
        "id": "wxd8E8r4_m1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris_data = pd.read_csv(\"/content/drive/MyDrive/Applied ML/Lab-3/iris.csv\", header = None)\n",
        "# changing the labels of the target columns\n",
        "iris_data[4] = iris_data[4].map({'Iris-setosa': 0,\n",
        "              'Iris-versicolor': 1,\n",
        "              'Iris-virginica': 2}) "
      ],
      "metadata": {
        "id": "Qpf-wjtFIGSi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separating features and targets\n",
        "X = iris_data.iloc[:,:-1].values\n",
        "y = iris_data.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "qBzzJwDezqaW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_mins_iris = [5, 10, 15, 20]"
      ],
      "metadata": {
        "id": "hZS3NlmL0B81"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe to record accuracy and standard deviation\n",
        "iris_results = pd.DataFrame(columns = ['N Min', 'Avg Accuracy', 'Standard Deviation'])"
      ],
      "metadata": {
        "id": "gExkZMBi4OQ1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and testing with each n_min\n",
        "for val in n_mins_iris:\n",
        "  acc, sd = train_test(X, y, val)\n",
        "  iris_results = iris_results.append({'N Min': val, 'Avg Accuracy': acc, 'Standard Deviation': sd}, ignore_index=True)"
      ],
      "metadata": {
        "id": "wrDZmrHP0QaG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(iris_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9279Ao2TB_4a",
        "outputId": "caf57407-9164-44da-d35a-e36dd16fe5db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   N Min  Avg Accuracy  Standard Deviation\n",
            "0    5.0      0.933333            0.078881\n",
            "1   10.0      0.933333            0.078881\n",
            "2   15.0      0.933333            0.078881\n",
            "3   20.0      0.933333            0.078881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Iris Results**\n",
        "\n",
        "\n",
        "1.   n_min = 5\n",
        "  *  Avg Accuracy = 0.933333 \n",
        "  * Standard Deviation = 0.078881\n",
        "\n",
        "2.   n_min = 10\n",
        "  *  Avg Accuracy = 0.933333 \n",
        "  * Standard Deviation = 0.078881\n",
        "            \n",
        "3.   n_min = 15\n",
        "  *  Avg Accuracy = 0.933333 \n",
        "  * Standard Deviation = 0.078881\n",
        "            \n",
        "4.   n_min = 20\n",
        "  *  Avg Accuracy = 0.933333 \n",
        "  * Standard Deviation = 0.078881\n",
        "           \n",
        "5.   n_min = 25\n",
        "  *  Avg Accuracy = 0.933333 \n",
        "  * Standard Deviation = 0.078881"
      ],
      "metadata": {
        "id": "TF3YCmXnuM3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Spam Base**"
      ],
      "metadata": {
        "id": "dmcu5DNrEdHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam_data = pd.read_csv(\"/content/drive/MyDrive/Applied ML/Lab-3/spambase.csv\", header = None)\n",
        "# separating features and targets\n",
        "X2 = spam_data.iloc[:,:-1].values\n",
        "y2= spam_data.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "zph4mmzTEkUt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_mins_spam = [5, 10, 15, 20, 25]"
      ],
      "metadata": {
        "id": "QaeZi4etE29e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataframe to store accuracy and standard deviation for each n_min\n",
        "spam_results = pd.DataFrame(columns = ['N Min', 'Avg Accuracy', 'Standard Deviation'])"
      ],
      "metadata": {
        "id": "ognTlaiBE83l"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for val in n_mins_spam:\n",
        "  acc, sd = train_test(X2, y2, val)\n",
        "  spam_results = spam_results.append({'N Min': val, 'Avg Accuracy': acc, 'Standard Deviation': sd}, ignore_index=True)\n",
        "  print(spam_results)"
      ],
      "metadata": {
        "id": "90wPzBseFAlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3469e452-086e-422e-a241-1f202a4ed6b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   N Min  Avg Accuracy  Standard Deviation\n",
            "0    5.0       0.87373            0.062572\n",
            "   N Min  Avg Accuracy  Standard Deviation\n",
            "0    5.0      0.873730            0.062572\n",
            "1   10.0      0.871562            0.066349\n",
            "   N Min  Avg Accuracy  Standard Deviation\n",
            "0    5.0      0.873730            0.062572\n",
            "1   10.0      0.871562            0.066349\n",
            "2   15.0      0.840285            0.074703\n",
            "   N Min  Avg Accuracy  Standard Deviation\n",
            "0    5.0      0.873730            0.062572\n",
            "1   10.0      0.871562            0.066349\n",
            "2   15.0      0.840285            0.074703\n",
            "3   20.0      0.823764            0.102280\n",
            "   N Min  Avg Accuracy  Standard Deviation\n",
            "0    5.0      0.873730            0.062572\n",
            "1   10.0      0.871562            0.066349\n",
            "2   15.0      0.840285            0.074703\n",
            "3   20.0      0.823764            0.102280\n",
            "4   25.0      0.783327            0.101522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(spam_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEfw8sILDKPC",
        "outputId": "867d6252-16e2-4ea2-c34a-a724782a652f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   N Min  Avg Accuracy  Standard Deviation\n",
            "0    5.0      0.873730            0.062572\n",
            "1   10.0      0.871562            0.066349\n",
            "2   15.0      0.840285            0.074703\n",
            "3   20.0      0.823764            0.102280\n",
            "4   25.0      0.783327            0.101522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spambase Results**\n",
        "\n",
        "\n",
        "1.   n_min = 5\n",
        "  *  Avg Accuracy = 0.873730\n",
        "  * Standard Deviation = 0.062572\n",
        "\n",
        "2.   n_min = 10\n",
        "  * Average Accuracy = 0.871562\n",
        "  * Standard Deviation = 0.066349\n",
        "            \n",
        "3.   n_min = 15\n",
        "  * Average Accuracy = 0.840285\n",
        "  * Standard Deviation = 0.074703\n",
        "            \n",
        "4.   n_min = 20\n",
        "  * Average Accuracy = 0.823764 \n",
        "  * Standard Deviation = 0.102280\n",
        "           \n",
        "5.   n_min = 25\n",
        "  * Average Accuracy = 0.783327 \n",
        "  * Standard Deviation = 0.101522\n",
        "           \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wCBPWq6etJJ8"
      }
    }
  ]
}