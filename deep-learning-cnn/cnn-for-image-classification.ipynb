{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Image classification is the process of taking an input (like a picture) and outputting a class (like “cat”) or a probability that the input is a particular class (“there’s a 90% probability that this input is a cat”). You can look at a picture and know that you’re looking at a terrible shot of your own face, but how can a computer learn to do that? With a convolutional neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Goals\n",
    "We would like you to establish a neural network involving advance DNN modules (i.e. convolution layers, RELU, pooling and fully connection layers and etc.)  to distinguish the specific category of an input image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## Packages\n",
    "Let's first import the necessary packages,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import warnings\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.jit.annotations import Optional, Tuple\n",
    "from torch import Tensor\n",
    "import os\n",
    "import numpy as np\n",
    "import os.path\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import IntProgress\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## GPU Device Configuration\n",
    "Then, we set up and configure our computational devices: \n",
    "Whether we use GPU or perform the calculation on CPU.\n",
    "we use the torch.devices() and torch.cude.is_available() functions to configure our computational devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Configuration\n",
    "### hyper parameters\n",
    "We then set up and hyper parameters that need for the our model.\n",
    "we need to define several hyper parameters for our model:\n",
    "1. learning rate\n",
    "2. batch size when training\n",
    "3. batch size when testing\n",
    "4. numbper of epoches\n",
    "5. out put directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBatchSize = 8\n",
    "testBatchSize = 8\n",
    "learningRate = 0.001\n",
    "num_epochs = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##  Data Loading\n",
    "Next, we are going to load our data. \n",
    "### We need to prepare our data:\n",
    "\n",
    "### We first import necessary librarys for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "###  Image processing\n",
    "Then, we define a image preprocessing object that our dataloader can directly use this object to preprocess our data\n",
    "We use the pytorch API to preform the data processing.\n",
    "1. Use transforms.Compose()\n",
    "2. Use .RandomHorizontalFlip()\n",
    "3. You add any extra transforms you like.\n",
    "4. Create this transform for both training set and testting set. Note that the testing spilit do not require any transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### We then download and prepare the data with the transforms defined above:\n",
    "1. Use command torchvision.datasets.CIFAR10() with root, train, download and transform posional arguments.\n",
    "2. Use the same command to create both train split and test split.\n",
    "3. Use torch.utils.data.DataLoader() to create the data loader based on the data we have.\n",
    "3. Use this command for both training split data loader and test split data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = dset.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "train_loader = data.DataLoader(dataset=train_set, batch_size=trainBatchSize, shuffle=True)\n",
    "test_set = dset.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "test_loader = data.DataLoader(dataset=test_set, batch_size=testBatchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##  Network\n",
    "Next, we are going to design our GoogLeNet\n",
    "### First, we define our GoogLeNet class\n",
    "### You need to refer the paper below to understand the structure.\n",
    "### https://arxiv.org/abs/1409.4842\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Inception Module with dimension reductions (There exist many implement methods)\n",
    "1. Create a python class called Inception which inherits nn.module\n",
    "\n",
    "2. Create a init function to init this python class\n",
    "    1. Require in_planes, kernel_1_x, kernel_3_in, kernel_3_x, kernel_5_in, kernel_5_x and pool_planes 7 arguments.\n",
    "    \n",
    "    2. Consists of 4 variables b1,b2,b3,b4\n",
    "    \n",
    "    3. b1 is a block consists of 2D convolution, a 2D batch normalization layer and a ReLU activation function\n",
    "    \n",
    "    4. b2 is a block consists of two 2D convolutions, two 2D batch normalization layers and tow ReLU activation functions\n",
    "    \n",
    "    5. b3 is a block consists of two 2D convolutions, two 2D batch normalization layers and two ReLU activation functions\n",
    "    \n",
    "    6. b4 is a block consists of a Maxpooling layer, a 2D convolution, a 2D batch normalization layer and a ReLU activation function\n",
    "    \n",
    "3. Create the forward function\n",
    "\n",
    "    1. this forward function will forward the input function though every block and return the concatenation of all the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_planes, kernel_1_x, kernel_3_in, kernel_3_x, kernel_5_in, kernel_5_x, pool_planes):\n",
    "        super(Inception, self).__init__()\n",
    "        # 1x1 conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, kernel_1_x, kernel_size=1),\n",
    "            nn.BatchNorm2d(kernel_1_x),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # 1x1 conv -> 3x3 conv branch\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, kernel_3_in, kernel_size=1),\n",
    "            nn.BatchNorm2d(kernel_3_in),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(kernel_3_in, kernel_3_x, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(kernel_3_x),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "\n",
    "        # 1x1 conv -> 5x5 conv branch\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, kernel_5_in, kernel_size=1),\n",
    "            nn.BatchNorm2d(kernel_5_in),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(kernel_5_in, kernel_5_x, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(kernel_5_x),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # 3x3 pool -> 1x1 conv branch\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
    "            nn.BatchNorm2d(pool_planes),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat(\n",
    "            [self.b1(x), self.b2(x), self.b3(x), self.b4(x)], 1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### GoogLeNet Module (There exist many implement methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Create a python class called GoogLeNet which inherits nn.module\n",
    "\n",
    "2. Create a init function to init this python class\n",
    "\n",
    "    1. Consists of a variables that serves as all layers before the inception, which contains a 2D convolution with padding=1, kernel_size=3 output channel=192, a 2D batch normalization layer and a ReLU activation fucntion.\n",
    "    \n",
    "    2. Two Inception blocks\n",
    "    \n",
    "    3. Maxpooling layer\n",
    "    \n",
    "    4. Five Inception blocks\n",
    "    \n",
    "    5. Maxpooling layer\n",
    "    \n",
    "    6. Two Inception blocks  \n",
    "    \n",
    "    7. Average Pooling layer\n",
    "    \n",
    "    8. A fully connected layer.\n",
    "    \n",
    "3. Create the forward function\n",
    "\n",
    "    1. this forward function will forward the input function though every block and return the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        # 2D convolution with padding=1, kernel_size=3 output channel=192, a 2D batch normalization layer and a ReLU activation fucntion.\n",
    "        self.conv1 = nn.Sequential(\n",
    "        nn.Conv2d(3, 192, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(192),\n",
    "        nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        # Two Inception blocks\n",
    "        self.inception1 = Inception(192,  64,  96, 128, 16,  32,  32)\n",
    "        self.inception2 = Inception(256, 128, 128, 192, 32,  96,  64)\n",
    "        \n",
    "        # Maxpooling layer\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Five Inception blocks\n",
    "        self.inception3 = Inception(480, 192,  96, 208, 16,  48,  64)\n",
    "        self.inception4 = Inception(512, 160, 112, 224, 24,  64,  64)\n",
    "        self.inception5 = Inception(512, 128, 128, 256, 24,  64,  64)\n",
    "        self.inception6 = Inception(512, 112, 144, 288, 32,  64,  64)\n",
    "        self.inception7 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        \n",
    "        # Maxpooling layer\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Two Inception blocks\n",
    "        self.inception8 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception9 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        # Average Pooling layer\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=8, stride=1)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        # A fully connected layer.\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.inception3(x)\n",
    "        x = self.inception4(x)\n",
    "        x = self.inception5(x)\n",
    "        x = self.inception6(x)\n",
    "        x = self.inception7(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.inception8(x)\n",
    "        x = self.inception9(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we create the network and send it to the target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (inception1): Inception(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (inception2): Inception(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception3): Inception(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (inception4): Inception(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (inception5): Inception(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (inception6): Inception(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (inception7): Inception(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (inception8): Inception(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (inception9): Inception(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = GoogLeNet()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, We create:\n",
    " 1. an optimizer  (we use adam optimzer here)\n",
    " 2. A Criterion (CrossEntropy) function\n",
    " 3. A Scheduler which is used to decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=learningRate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = MultiStepLR(optimizer, \n",
    "                        milestones=[10, 20], # List of epoch indices\n",
    "                        gamma =0.4) # Multiplicative factor of learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "##  Training\n",
    "Then, we are going to train our Network\n",
    "\n",
    "1. Set our network to the training model.\n",
    "2. Init the train loss, total data and number corrected predictions. \n",
    "3. For each data in the training split\n",
    "    1. Put the data to the correct devices using .to()\n",
    "    2. Reset the gradient of the optimzier.\n",
    "    3. Feed the data forward to the google net\n",
    "    4. Use the criterion function to compute the loss term\n",
    "    5. Backprop the loss\n",
    "    6. Update the network parameters using the optimzier\n",
    "    7. Accumulate the training loss\n",
    "    8. Find the prediciton. hint: using torch.max()\n",
    "    9. Increment the data size\n",
    "    10. Increment the corrected prediction\n",
    "    11. Print log\n",
    "    \n",
    "-----\n",
    "##  Testing\n",
    "Then, we are going to test our module\n",
    "\n",
    "1. Set our network to the test model.\n",
    "2. Init the test loss, total data and number corrected predictions. \n",
    "3. For each data in the training split, we warp it using torch.no_grad()\n",
    "    1. Put the data to the correct devices using .to()\n",
    "    2. Feed the data forward to the google net\n",
    "    3. Use the criterion function to compute the loss term\n",
    "    4. Accumulate the training loss\n",
    "    5. Find the prediciton. hint: using torch.max()\n",
    "    6. Increment the data size\n",
    "    7. Increment the corrected prediction\n",
    "    8. Print log\n",
    "\n",
    "-----\n",
    "##  Epochs:\n",
    "For each epoch:\n",
    "1. we first step our scheduler\n",
    "2. we train our module\n",
    "3. we test our module\n",
    "4. we update the testing accuracy\n",
    "5. we save the module at the end and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/26: 100%|██████████| 6250/6250 [03:27<00:00, 30.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Train Acc. => 43.356% | Train Loss => 9724.91633\n",
      "Test Acc.  => 57.920% | Test Loss  => 1490.45351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/26: 100%|██████████| 6250/6250 [03:27<00:00, 30.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n",
      "Train Acc. => 65.320% | Train Loss => 6282.78597\n",
      "Test Acc.  => 70.450% | Test Loss  => 1093.47874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/26: 100%|██████████| 6250/6250 [03:26<00:00, 30.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n",
      "Train Acc. => 73.408% | Train Loss => 4870.20385\n",
      "Test Acc.  => 73.770% | Test Loss  => 974.61906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/26: 100%|██████████| 6250/6250 [03:27<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n",
      "Train Acc. => 77.752% | Train Loss => 4083.08672\n",
      "Test Acc.  => 78.910% | Test Loss  => 789.02230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/26: 100%|██████████| 6250/6250 [03:26<00:00, 30.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n",
      "Train Acc. => 80.642% | Train Loss => 3548.57625\n",
      "Test Acc.  => 80.910% | Test Loss  => 704.57627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/26: 100%|██████████| 6250/6250 [03:26<00:00, 30.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6\n",
      "Train Acc. => 83.104% | Train Loss => 3090.79303\n",
      "Test Acc.  => 81.200% | Test Loss  => 690.91507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/26: 100%|██████████| 6250/6250 [03:24<00:00, 30.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7\n",
      "Train Acc. => 84.816% | Train Loss => 2763.58940\n",
      "Test Acc.  => 83.250% | Test Loss  => 620.51523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/26: 100%|██████████| 6250/6250 [03:27<00:00, 30.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8\n",
      "Train Acc. => 86.562% | Train Loss => 2469.13344\n",
      "Test Acc.  => 83.740% | Test Loss  => 608.58902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/26: 100%|██████████| 6250/6250 [03:23<00:00, 30.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9\n",
      "Train Acc. => 87.764% | Train Loss => 2216.41628\n",
      "Test Acc.  => 84.840% | Test Loss  => 559.18066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/26: 100%|██████████| 6250/6250 [03:26<00:00, 30.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10\n",
      "Train Acc. => 88.890% | Train Loss => 2028.55393\n",
      "Test Acc.  => 85.500% | Test Loss  => 559.41747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/26: 100%|██████████| 6250/6250 [03:27<00:00, 30.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11\n",
      "Train Acc. => 92.374% | Train Loss => 1385.85027\n",
      "Test Acc.  => 87.700% | Test Loss  => 480.33136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/26: 100%|██████████| 6250/6250 [03:25<00:00, 30.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12\n",
      "Train Acc. => 93.666% | Train Loss => 1145.83752\n",
      "Test Acc.  => 87.610% | Test Loss  => 471.42403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/26: 100%|██████████| 6250/6250 [03:26<00:00, 30.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13\n",
      "Train Acc. => 94.356% | Train Loss => 1035.00345\n",
      "Test Acc.  => 87.930% | Test Loss  => 468.70844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/26: 100%|██████████| 6250/6250 [03:29<00:00, 29.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14\n",
      "Train Acc. => 95.006% | Train Loss => 921.06822\n",
      "Test Acc.  => 87.740% | Test Loss  => 503.93878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/26: 100%|██████████| 6250/6250 [03:28<00:00, 29.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15\n",
      "Train Acc. => 95.530% | Train Loss => 816.33449\n",
      "Test Acc.  => 88.430% | Test Loss  => 485.35880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/26: 100%|██████████| 6250/6250 [03:21<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16\n",
      "Train Acc. => 95.900% | Train Loss => 734.84815\n",
      "Test Acc.  => 88.070% | Test Loss  => 498.41961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/26: 100%|██████████| 6250/6250 [03:21<00:00, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17\n",
      "Train Acc. => 96.390% | Train Loss => 653.27584\n",
      "Test Acc.  => 88.180% | Test Loss  => 528.93467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/26: 100%|██████████| 6250/6250 [03:27<00:00, 30.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18\n",
      "Train Acc. => 96.700% | Train Loss => 594.38892\n",
      "Test Acc.  => 88.490% | Test Loss  => 525.10855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/26: 100%|██████████| 6250/6250 [03:26<00:00, 30.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19\n",
      "Train Acc. => 96.938% | Train Loss => 559.52342\n",
      "Test Acc.  => 88.530% | Test Loss  => 555.86724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/26: 100%|██████████| 6250/6250 [03:26<00:00, 30.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 20\n",
      "Train Acc. => 97.126% | Train Loss => 505.39508\n",
      "Test Acc.  => 88.220% | Test Loss  => 552.67397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/26: 100%|██████████| 6250/6250 [03:26<00:00, 30.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 21\n",
      "Train Acc. => 98.162% | Train Loss => 328.78983\n",
      "Test Acc.  => 89.310% | Test Loss  => 530.98977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/26: 100%|██████████| 6250/6250 [03:25<00:00, 30.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 22\n",
      "Train Acc. => 98.632% | Train Loss => 252.70968\n",
      "Test Acc.  => 88.960% | Test Loss  => 551.99168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/26: 100%|██████████| 6250/6250 [03:23<00:00, 30.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 23\n",
      "Train Acc. => 98.778% | Train Loss => 228.02870\n",
      "Test Acc.  => 89.250% | Test Loss  => 559.00306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/26: 100%|██████████| 6250/6250 [03:24<00:00, 30.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 24\n",
      "Train Acc. => 98.932% | Train Loss => 200.42805\n",
      "Test Acc.  => 89.360% | Test Loss  => 581.13318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/26: 100%|██████████| 6250/6250 [03:25<00:00, 30.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 25\n",
      "Train Acc. => 99.068% | Train Loss => 171.64909\n",
      "Test Acc.  => 89.410% | Test Loss  => 564.47889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/26: 100%|██████████| 6250/6250 [03:26<00:00, 30.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 26\n",
      "Train Acc. => 99.072% | Train Loss => 178.74762\n",
      "Test Acc.  => 89.360% | Test Loss  => 588.41440\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    accumulated_loss = .0 # accumulated training loss\n",
    "    correct = 0 # number of correct predictions\n",
    "    total = 0 # total data\n",
    "    for data in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # get the inputs and put them to the correct device\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # reset the optimizer gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward it to google net\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backprop the loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the params\n",
    "        optimizer.step()\n",
    "        \n",
    "        accumulated_loss += loss.item() # accumulate the training lsos\n",
    "        _, predicted = torch.max(outputs.data, 1) # find the prediction\n",
    "        total += labels.size(0) # increment the data size\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss.append(accumulated_loss)\n",
    "    current_train_acc = correct / total # calculate accuracy\n",
    "    train_acc.append(current_train_acc)\n",
    "    \n",
    "    # printing the log\n",
    "    print('\\nEpoch: {}'.format(epoch+1))\n",
    "    print('Train Acc. => {:.3f}%'.format(100 * current_train_acc), end=' | ')\n",
    "    print('Train Loss => {:.5f}'.format(accumulated_loss))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_accumulated_loss = .0 # accumulated test loss\n",
    "        correct = 0 # correct predictions\n",
    "        total = 0 # total data\n",
    "        for data in test_loader:\n",
    "            # get the inputs and send them to correct device\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # feed forwards\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            # compute the loss term\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_accumulated_loss += loss.item() # accumulate test loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_loss.append(test_accumulated_loss)\n",
    "        current_test_acc = correct / total\n",
    "        test_acc.append(current_test_acc)\n",
    "        \n",
    "        print('Test Acc.  => {:.3f}%'.format(100 * current_test_acc), end=' | ')\n",
    "        print('Test Loss  => {:.5f}'.format(test_accumulated_loss))\n",
    "    \n",
    "    scheduler.step() # stepping the sceduler at the end as suggested due to the update\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA7i0lEQVR4nO3deXxU5b348c93JpN9EgiQhD2ABATCvmsVRYFaq7YWl6qAteKuvfdq1fuzar211a6ulWvdRVHrvmBVEK9LkVUUkVUJEEC2sGXfvr8/zkkYIAmTZTLJzPf9ep3XOeeZc2a+J4H55jzPc55HVBVjjDGmsTzhDsAYY0zbZonEGGNMk1giMcYY0ySWSIwxxjSJJRJjjDFNYonEGGNMk1giMcYY0ySWSIwJERHJFZHTwh2HMaFmicQYY0yTWCIxpgWJSJyI3Cci29zlPhGJc1/rKCJvi8g+EckXkU9ExOO+drOIbBWRgyKyVkQmhvdKjDkkJtwBGBNl/h8wFhgKKPAGcBvwG+C/gDygk3vsWEBFpB9wLTBKVbeJSBbgbdmwjamb3ZEY07IuAu5S1Z2qugv4LXCJ+1o50BnoqarlqvqJOoPhVQJxwAAR8alqrqp+G5bojamFJRJjWlYXYFPA/ia3DOBPwAbgfRH5TkRuAVDVDcCvgDuBnSLygoh0wZhWwhKJMS1rG9AzYL+HW4aqHlTV/1LV3sCPgf+sbgtR1edV9UT3XAXubdmwjambJRJjQssnIvHVCzAHuE1EOolIR+B2YDaAiJwpIseJiAAHcKq0KkWkn4ic6jbKlwDF7mvGtAqWSIwJrbk4X/zVSzywFPgKWAksB37nHtsXmAcUAAuBv6vqRzjtI/cAu4HvgXTgv1vsCow5BrGJrYwxxjSF3ZEYY4xpEkskxhhjmsQSiTHGmCaxRGKMMaZJom6IlI4dO2pWVla4wzDGmDZl2bJlu1W1U22vhSyRiMgTwJnATlUd5JalAS8CWUAucJ6q7nVfuxW4DKd//PWq+p5bPgJ4CkjA6Up5g6qq26f+GWAEsAc4X1VzjxVXVlYWS5cubbbrNMaYaCAim+p6LZRVW08BU44ouwWYr6p9gfnuPiIyALgAGOie83cRqR6U7hFgJk4f+74B73kZsFdVjwP+hj3pa4wxYRGyRKKqHwP5RxSfDTztbj8NnBNQ/oKqlqrqRpzxhkaLSGcgRVUXuoPXPXPEOdXv9TIw0X0i2BhjTAtq6cb2DFXdDuCu093yrsCWgOPy3LKu7vaR5Yedo6oVwH6gQ8giN8YYU6vW0the252E1lNe3zlHv7nITJzqMXr06NGY+IxpNuXl5eTl5VFSUhLuUIw5Snx8PN26dcPn8wV9Tksnkh0i0llVt7vVVjvd8jyge8Bx3XBGRM1zt48sDzwnT0RigFSOrkoDQFUfBR4FGDlypI0JY8IqLy8Pv99PVlYWVhtrWhNVZc+ePeTl5dGrV6+gz2vpqq03genu9nSc2eGqyy9wpyHthdOovtit/jooImPd9o9pR5xT/V4/Az5UGzjMtAElJSV06NDBkohpdUSEDh06NPhuOZTdf+cAE4COIpIH3IEzgulLInIZsBmYCqCqq0TkJeAboAK4RlWrh8m+ikPdf991F4DHgWdFZAPOncgFoboWY5qbJRHTWjXm32bIEomqXljHSxPrOP5u4O5aypcCg2opL8FNRC1haW4+89fs5NeT+9mXgDHGBLAhUoK0cut+HvnoW3YdLA13KMY0i9deew0RYc2aNeEO5ShZWVns3r273mN+//vfN/h9n3rqKa699trDyp588kmGDh3K0KFDiY2NJScnh6FDh3LLLbcE9Z6333478+bNq/eYN998k3vuuafB8dZmxowZvPzyy83yXs3FEkmQ+mX4AVi3oyDMkRjTPObMmcOJJ57ICy+8EO5QGqUxiaQ2l156KStWrGDFihV06dKFBQsWsGLFisO++Csr656Q8q677uK0006r9zPOOuusoBNTW2SJJEjZmU4iWbvjYJgjMabpCgoK+Oyzz3j88ccPSySVlZXceOON5OTkMHjwYB588EEAlixZwvjx4xkyZAijR4/m4MGDR/11f+aZZ/LRRx8BkJyczM0338yIESM47bTTWLx4MRMmTKB37968+eabwNF3B4HnBzrnnHMYMWIEAwcO5NFHHwXglltuobi4mKFDh3LRRRcBMHv2bEaPHs3QoUO54oorar78n3zySbKzszn55JP57LPPgv4ZJScnc/vttzNmzBgWLlzIXXfdxahRoxg0aBAzZ86kum9P4B1CVlYWd9xxB8OHDycnJ6fmbi/wWmfMmMH111/P+PHj6d27d825VVVVXH311QwcOJAzzzyTM844I+g7j5KSEi699FJycnIYNmwYCxYsAGDVqlU1P5PBgwezfv16CgsL+dGPfsSQIUMYNGgQL774YtA/k7q0ludIWr2OyXF0SIpl3feWSEzz+e1bq/hm24Fmfc8BXVK448cD6z3m9ddfZ8qUKWRnZ5OWlsby5csZPnw4jz76KBs3buSLL74gJiaG/Px8ysrKOP/883nxxRcZNWoUBw4cICEhod73LywsZMKECdx777385Cc/4bbbbuODDz7gm2++Yfr06Zx11llBX88TTzxBWloaxcXFjBo1inPPPZd77rmHhx56iBUrVgCwevVqXnzxRT777DN8Ph9XX301zz33HKeffjp33HEHy5YtIzU1lVNOOYVhw4YF9bmFhYUMGjSIu+66C4ABAwZw++23A3DJJZfw9ttv8+Mf//io8zp27Mjy5cv5+9//zp///Gcee+yxo47Zvn07n376KWvWrOGss87iZz/7Ga+++iq5ubmsXLmSnTt3cvzxx/OLX/wiqFgffvhhAFauXMmaNWuYNGkS69atY9asWdxwww1cdNFFlJWVUVlZydy5c+nSpQvvvPMOAPv37w/qM+pjdyQNkJ3htzsSExHmzJnDBRc4HR0vuOAC5syZA8C8efO48soriYlx/sZMS0tj7dq1dO7cmVGjRgGQkpJS83pdYmNjmTLFGRYvJyeHk08+GZ/PR05ODrm5uQ2K9YEHHmDIkCGMHTuWLVu2sH79+qOOmT9/PsuWLWPUqFEMHTqU+fPn891337Fo0SImTJhAp06diI2N5fzzzw/6c71eL+eee27N/oIFCxgzZgw5OTl8+OGHrFq1qtbzfvrTnwIwYsSIOq/1nHPOwePxMGDAAHbs2AHAp59+ytSpU/F4PGRmZnLKKacEHeunn37KJZdcAkD//v3p2bMn69atY9y4cfz+97/n3nvvZdOmTSQkJJCTk8O8efO4+eab+eSTT0hNTQ36c+pidyQNkJ2RzMvL8lBV67llmsWx7hxCYc+ePXz44Yd8/fXXiAiVlZWICH/84x9r/bdd17/3mJgYqqqqavYDnz3w+Xw153g8HuLi4mq2Kyoqjnl+tY8++oh58+axcOFCEhMTmTBhQq3HqSrTp0/nD3/4w2Hlr7/+eqP/r8bHx+P1emtiu/rqq1m6dCndu3fnzjvvrPNZi+pr9Xq9Ndda1zHVsQeuG6Ouc3/+858zZswY3nnnHSZPnsxjjz3GqaeeyrJly5g7dy633norkyZNqrnTaiy7I2mA7Ew/hWWVbN1XHO5QjGm0l19+mWnTprFp0yZyc3PZsmULvXr14tNPP2XSpEnMmjWr5gswPz+f/v37s23bNpYsWQLAwYMHqaioICsrixUrVlBVVcWWLVtYvHhxg+II5vz9+/fTvn17EhMTWbNmDZ9//nnNaz6fj/LycgAmTpzIyy+/zM6dO2vi3rRpE2PGjOGjjz5iz549lJeX889//rNRP7PqpNGxY0cKCgpC0mvqxBNP5JVXXqGqqoodO3bU2l5Ul5NOOonnnnsOgHXr1rF582b69evHd999R+/evbn++us566yz+Oqrr9i2bRuJiYlcfPHF3HjjjSxfvrzJsdsdSQMc6rl1kG7tE8McjTGNM2fOnKN6EJ177rk8//zzPPjgg6xbt47Bgwfj8/m4/PLLufbaa3nxxRe57rrrKC4uJiEhgXnz5nHCCSfQq1cvcnJyGDRoEMOHD29QHMGcP2XKFGbNmsXgwYPp168fY8eOrXlt5syZDB48mOHDh/Pcc8/xu9/9jkmTJlFVVYXP5+Phhx9m7Nix3HnnnYwbN47OnTszfPjwentg1aVdu3Zcfvnl5OTkkJWVVVPN15zOPfdc5s+fz6BBg8jOzmbMmDF1VjtdccUV/OpXvwKge/fuLFiwgCuvvJKcnBxiYmJ46qmniIuL48UXX2T27Nn4fD4yMzO5/fbbWbJkCTfddBMejwefz8cjjzzS5Ngl2kYVGTlypDZ2Yqv9xeUM+e373DylP1dN6NPMkZlosXr1ao4//vhwh2FaoYKCApKTk9mzZw+jR4/ms88+IzMzs8XjqO3fqIgsU9WRtR1vdyQNkJrgIzMlnvXW4G6MCYEzzzyTffv2UVZWxm9+85uwJJHGsETSQNmZ1nPLGBMaDWkXaU2ssb2B+mUks35nAZVV0VUlaIwxdbFE0kDZGX7KKqrYtKcw3KEYY0yrYImkgbJtzC1jjDmMJZIG6puRDDhdgI0xxlgiabDE2Bh6pCVag7tp82wYeUdTh5EHuO+++ygqKqrZP+OMM9i3b1+D4ztSbm4ugwYdNR1Tq2OJpBGyM/w2eKNp82wYeUcww8gfy5GJZO7cubRr165Z4msLLJE0QnZGMht3F1JWUXXsg41phWwY+WP705/+xKhRoxg8eDB33HEHQK1DsD/wwANs27aNU045pWagxeo7qtzcXI4//nguv/xyBg4cyKRJkyguLq75mQ4ePJhx48Zx0003NejOY/78+QwbNoycnBx+8YtfUFpaWvNzGTBgAIMHD+bGG28E4J///CeDBg1iyJAhnHTSSUF/RkPYcySN0C/TT0WVsnF3If3ceUqMaZR3b4HvVzbve2bmwA/r/2vahpGv3/vvv8/69etZvHgxqspZZ53Fxx9/zK5du44agj01NZW//vWvLFiwgI4dOx71XuvXr2fOnDn84x//4LzzzuOVV17h4osv5tJLL+XRRx9l/PjxDapGKykpYcaMGcyfP5/s7GymTZvGI488wrRp03jttddYs2YNIlJTtXbXXXfx3nvv0bVr12apbquN3ZE0QnXPLWsnMW2VDSNfv/fff5/333+fYcOGMXz4cNasWcP69esbNQR7r169GDp0KHBoaPl9+/Zx8OBBxo8fDzij9AZr7dq19OrVi+zsbACmT5/Oxx9/TEpKCvHx8fzyl7/k1VdfJTHRGQ/whBNOYMaMGfzjH/9o1DhjwbA7kkbo3SkJr0ecdpIh4Y7GtGnHuHMIBRtG/thUlVtvvZUrrrjiqNcaOgR74JDxXq+X4uLikAwZHxMTw+LFi5k/fz4vvPACDz30EB9++CGzZs1i0aJFvPPOOwwdOpQVK1bQoUOHRn9+beyOpBHiYrxkdbCeW6ZtsmHkj23y5Mk88cQTFBQ4z4tt3bqVnTt31jkEu9/v5+DB4L8P2rdvj9/vr7mehnR46N+/P7m5uWzYsAGAZ599lpNPPpmCggL279/PGWecwX333VdT7fftt98yZswY7rrrLjp27MiWLVuC/qxg2R1JI/XL9Df7FKnGtAQbRv7Y1TuTJk1i9erVjBs3DnA6D8yePZsNGzbUOgT7zJkz+eEPf0jnzp1r5ks/lscff5zLL7+cpKQkJkyYUGc12dq1a+nWrVvN/t/+9jeefPJJpk6dSkVFBaNGjeLKK68kPz+fs88+m5KSElSVv/3tbwDcdNNNrF+/HlVl4sSJDBnS/NUoNox8I903bx33z1/PN7+dQkKstxkiM9HChpE3cGjIeIB77rmH7du3c//994c5KkdDh5G3qq1G6pfhRxU27LShUowxDVfdZjFo0CA++eQTbrvttnCH1GhWtdVIfQN6buV0O3bPDWOMCXT++ecH3YustbM7kkbK6pBIrNdjk1yZRom2KmXTdjTm36YlkkaK8Xrok55sPbdMg8XHx7Nnzx5LJqbVUVX27NlDfHx8g86zqq0m6JeRzOKN+eEOw7Qx3bp1Iy8vj127doU7FGOOEh8ff1gvsWBYImmCvhl+Xl+xjQMl5aTE+8IdjmkjfD4fvXr1CncYxjQbq9pqgn5ug/t6m+TKGBPFLJE0QfWAjTbJlTEmmlkiaYKu7RJIjPWy1uYmMcZEsbAkEhH5DxFZJSJfi8gcEYkXkTQR+UBE1rvr9gHH3yoiG0RkrYhMDigfISIr3dcekMaMztYEHo/QNz3Z7kiMMVGtxROJiHQFrgdGquogwAtcANwCzFfVvsB8dx8RGeC+PhCYAvxdRKrHJHkEmAn0dZcpLXgpgDtborWRGGOiWLiqtmKABBGJARKBbcDZwNPu608D57jbZwMvqGqpqm4ENgCjRaQzkKKqC9XpkP9MwDktpl+mn90FpewpKG3pjzbGmFahxROJqm4F/gxsBrYD+1X1fSBDVbe7x2wH0t1TugKB4x7nuWVd3e0jy48iIjNFZKmILG3uvvvVk1zZXYkxJlqFo2qrPc5dRi+gC5AkIhfXd0otZVpP+dGFqo+q6khVHdmpU6eGhlwv67lljIl24ajaOg3YqKq7VLUceBUYD+xwq6tw1zvd4/OA7gHnd8OpCstzt48sb1Hp/jhS4mMskRhjolY4EslmYKyIJLq9rCYCq4E3genuMdOBN9ztN4ELRCRORHrhNKovdqu/DorIWPd9pgWc02JEhH6Zfkskxpio1eJDpKjqIhF5GVgOVABfAI8CycBLInIZTrKZ6h6/SkReAr5xj79GVaunOLsKeApIAN51lxaXneHnrS+31Tm3tTHGRLKwjLWlqncAdxxRXIpzd1Lb8XcDd9dSvhQY1OwBNlC/TD/PLapgx4FSMlMbNmqmMca0dfZkezPom24N7saY6GWJpBlkZzjzLlsiMcZEI0skzaBDchwdk+NszC1jTFSyRNJM+mXamFvGmOhkiaSZ9E33s35nAVVVNn2qMSa6WCJpJv0y/RSVVbJ1X3G4QzHGmBZliaSZVI+5Ze0kxphoY4mkmVT33Fpr7STGmChjiaSZ+ON9dEmNZ70lEmNMlLFE0oyyM/2steHkjTFRxhJJM+qX4efbnQVUVFaFOxRjjGkxlkiaUXaGn7LKKnL3FIU7FGOMaTGWSJpRdc8taycxxkQTSyTN6Lj0ZESs55YxJrocM5GIyB9FJEVEfCIyX0R2H2Nq3KiVEOulZ1qiDZVijIkqwdyRTFLVA8CZONPbZgM3hTSqNiw7w28PJRpjokowicTnrs8A5qhqfgjjafOyM/zk7imitKLy2AcbY0wECCaRvCUia4CRwHwR6QSUhDastis7009llfLdrsJwh2KMMS3imIlEVW8BxgEjVbUcKATODnVgbVW/DJst0RgTXYJpbJ8KVKhqpYjcBswGuoQ8sjaqV8ckYjxi7STGmKgRTNXWb1T1oIicCEwGngYeCW1YbVdsjIdeHZNYZ0OlGGOiRDCJpLrV+EfAI6r6BhAbupDavuxMv1VtGWOiRjCJZKuI/C9wHjBXROKCPC9q9cvwszm/iKKyinCHYowxIRdMQjgPeA+Yoqr7gDTsOZJ6HRoqxaq3jDGRL5heW0XAt8BkEbkWSFfV90MeWRtWPcmVVW8ZY6JBML22bgCeA9LdZbaIXBfqwNqynh2SiI3xWCIxxkSFmCCOuQwYo6qFACJyL7AQeDCUgbVlXo/QNz3ZJrkyxkSFYNpIhEM9t3C3JTThRI5+GX7W2bMkxpgoEMwdyZPAIhF5zd0/B3g8ZBFFiOxMP69+sZX9xeWkJviOfYIxxrRRwTS2/xW4FMgH9rrbL4U4rjbv+M4pACzZaGNcGmMiWzB3JKjqcmB59b6IbAZ6hCqoSDC+Twc6+eN4btEmThuQEe5wjDEmZBr7YKG1kRyDz+vhwtE9+GjdLjbbHO7GmAjW2ESiTflQEWknIi+LyBoRWS0i40QkTUQ+EJH17rp9wPG3isgGEVkrIpMDykeIyEr3tQdEpFUluJ+P7oFHhNmLNoU7FGOMCZk6q7ZE5EFqTxgCtGvi594P/EtVfyYisUAi8N/AfFW9R0RuAW4BbhaRAcAFwECcUYfniUi2qlbiDB45E/gcmAtMAd5tYmzNJjM1nskDM3hp6Rb+8/Rs4n3ecIdkjDHNrr47kqXAslqWpUCjH0gUkRTgJNyeX6pa5g69cjbOyMK463Pc7bOBF1S1VFU3AhuA0SLSGUhR1YWqqsAzAee0GheP7cm+onLe+nJbuEMxxpiQqPOORFWfruu1JuoN7AKeFJEhOMnpBiBDVbe7n71dRNLd47vi3HFUy3PLyt3tI8uPIiIzce5c6NGjZfsIjOvdgb7pycz+fBNTR3Zv0c82xpiWEI5RfGOA4ThD0g/DmXHxlnqOr63dQ+spP7pQ9VFVHamqIzt16tTQeJtERLhkXE++zNvPl1v2tehnG2NMSwhHIskD8lR1kbv/Mk5i2eFWV+GudwYcH/infDdgm1verZbyVucnw7qSFOvlmYXW6G6MiTwtnkhU9Xtgi4j0c4smAt8AbwLT3bLpwBvu9pvABSISJyK9gL7AYrca7KCIjHV7a00LOKdV8cf7+Mnwrrz11Tb2FpaFOxxjjGlWjem1BYCqXt+Ez70OeM7tsfUdztPyHuAlEbkM2AxMdT9nlYi8hJNsKoBr3B5bAFcBTwEJOL21Wk2PrSNdMjaL2Z9v5qWlW7ji5D7hDscYY5pNfU+2L3XXJwADgBfd/ak4DeSNpqorgJG1vDSxjuPvBu6upXwpMKgpsbSUfpl+RvdKY/aiTfzyB73xelrVIy/GGNNodVZtqerTbs+tvsApqvqgqj6I82U/tIXiiyjTxvVkS34xH6/bFe5QjDGm2QTTRtIF8AfsJ7tlpoEmDcikkz+OZxbmhjsUY4xpNsEkknuAL0TkKRF5Cmfwxt+HNKoIFRtj428ZYyJPMMPIPwmMAV5zl3EhfFgx4lWPv/Wcjb9ljIkQwczZLsBpwBBVfQOIFZHRIY8sQmWmxjNpQAYvLt1CSXnlsU8wxphWLpiqrb8D44AL3f2DwMMhiygKXDLOGX/r7a+2hzsUY4xpsmASyRhVvQYoAVDVvUBsSKOKcON6d+C49GSetUZ3Y0wECCaRlIuIF/fhRBHpBFSFNKoIJyJcMtbG3zLGRIZgEskDOI3s6SJyN/Ap8IeQRhUFfjq8K4mxXp793BrdjTFtWzC9tp4Dfo2TPLYD56jqS6EOLNL54338ZFhX3vrSxt8yxrRtwfTaelZV16jqw6r6kKquFpFnWyK4SDdtXBalFVW8tHRLuEMxxphGC6Zqa2DgjtteMiI04USXwPG3qqrqHB/TGGNatToTiYjcKiIHgcEickBEDrr7O2mlw7W3RZeMdcbf+j8bf8sY00bVN2jjH1TVD/xJVVNU1e8uHVT11haMMaJNHuiMv2WN7saYtiqYxvZbRaS9iIwWkZOql5YILhpUj7+1YO1OtuTb+FvGmLYnmMb2XwIfA+8Bv3XXd4Y2rOhSPf7WbLsrMca0QcE0tt8AjAI2qeopwDDAKvSbkY2/ZYxpy4JJJCWqWgIgInGqugbod4xzTANVj7/17EK7KzHGtC3BJJI8EWkHvA58ICJvANtCGVQ0Gte7A6cdn8Ef31tjw6YYY9qUYBrbf6Kq+1T1TuA3wOPAOSGOK+qICH+eOph0fzzXzlnO/uLycIdkjDFBqe85krQjF2AlzlhbyS0WYRRplxjLgz8fxvZ9Jdzyyleo2kOKxpjWL6ae15bhjPgrtbymQO+QRBTlhvdoz6+n9OP3c9fwzMJNTB+fFe6QjDGmXnUmElXt1ZKBmEN+eWJvFn2Xz93vrGZEz/YM6poa7pCMMaZOwTxHclJtS0sEF608HuHPU4fQMTmWa55fzoESay8xxrRewfTauilg+Q3wFvZAYsi1T3LaS/L2FnPrKyutvcQY02oF02vrxwHL6cAgYEfoQzMjeqZx0+R+vLNyO7MXbQ53OMYYU6tg7kiOlIeTTEwLmPmD3kzo14n/eesbvt66P9zhGGPMUYJpI3lQRB5wl4eAT4AvQx+aAae95K/nDSUtKZZrn1/OQWsvMca0MsHckSzF6Qq8DFgI3KyqF4c0KnOYNLe9ZMveYm591dpLjDGtS33PkQCgqk+3RCCmfqOy0vjP07P503trGdenAxeN6RnukIwxBgiuautMEflCRPIDZko80BLBmcNddXIfTsruxG/f+oZvttmvwBjTOgRTtXUfMB3oEDBTYkpowzK1cdpLhtA+0cc1zy+noLQi3CEZY0xQiWQL8LVaxXyr0DE5jgcuGMamPYX8v9esvcQYE37BJJJfA3NF5FYR+c/qpakfLCJet8rsbXc/TUQ+EJH17rp9wLG3isgGEVkrIpMDykeIyEr3tQdEpLZxwSLOmN4d+I/TsnljxTYe/3RjuMMxxkS5YBLJ3UAREA/4A5amugFYHbB/CzBfVfsC8919RGQAcAEwEJgC/F1EvO45jwAzgb7uMqUZ4moTrj7lOCYNyOB376zmrx+sszsTY0zYHLPXFpCmqpOa80NFpBvwI5wkVX13czYwwd1+GvgIuNktf0FVS4GNIrIBGC0iuUCKqi503/MZnHlS3m3OWFsrr0f4+0XDufXVlTwwfz27C0r5n7MH4fVExU2ZMaYVCeaOZJ6INGsiwWnA/zVQFVCWoarbAdx1ulveFaedplqeW9bV3T6y/CgiMlNElorI0l27Ime6+Rivhz/+bDBXTejD84s2c81zy23Od2NMiwsmkVwD/EtEipuj+6+InAnsVNVlwZ5SS1l986QcXaj6qKqOVNWRnTp1CvJj2wYR4eYp/fnNmQP416rvmfHkYhst2BjTooIZtNGvqh5VTWim7r8nAGe5VVMvAKeKyGxgh4h0BnDXO93j84DuAed3w5kzPs/dPrI8Kl12Yi/uv2AoS3P3cv7/fs7OAyXhDskYEyVafD4SVb1VVbupahZOI/qH7pArb+I8r4K7fsPdfhO4QETiRKQXTqP6Yrf666CIjHV7a00LOCcqnT20K4/PGMWmPYWcO+vf5O4uDHdIxpgo0JrmI7kHOF1E1gOnu/uo6irgJeAb4F/ANapa3RBwFfAYsAH4lihpaK/PydmdeP7ysRSUVPCzWf+2EYONMSEnDe02KiLdgT+q6oWhCSm0Ro4cqUuXLg13GCH37a4Cpj2+mH1FZTw6bSQnHNcx3CEZY9owEVmmqiNre83mI4lQfTol88pV4+nWPpFLn1zC219FbfORMSbEjvkciYg8yKHeUB5gKDYfSZuQmRrPS1eM45fPLOG6OV+QX1jGtHFZ4Q7LGBNhgnkgMbAeqAKYo6qfhSge08xSE308e9kYrn3+C25/YxXb95dw46R+9uCiMabZBJNIXgZKqhu43TGyElW1KLShmeYS7/My6+Lh3P7mKh756Fu+3rqf+y8YRlpSbLhDM8ZEgGDaSOYDCQH7CcC80IRjQiXG6+H3P8nhnp/msGhjPj9+8FO+3LIv3GEZYyJAMIkkXlULqnfc7cTQhWRC6YLRPXjlyvEATJ21kOcWbbIBH40xTRJMIikUkeHVOyIyAigOXUgm1HK6pfL2dScyrk8H/t9rX3PjP7+yMbqMMY0WTBvJr4B/ikh1/9HOwPkhi8i0iPZJsTwxYxQPzF/PAx+uZ/X2A8y6eAQ9OtjNpjGmYYJ6IFFEfEA/nIES16hqmx0VMFoeSGyIBWt28qsXV6Cq/O38oUw8PiPcIRljWpkmPZAoItcASar6taquBJJF5OrmDtKEzyn903n7uhPpnpbIZU8v5S/vr6WyytpNjDHBCaaN5HJV3Ve9o6p7gctDFpEJi+5pibxy1XjOG9mNBz/cwIwnF5NfWBbusIwxbUAwicQTOBe6O82tPYAQgeJ9Xv74syGHdRFeYV2EjTHHEEwieQ94SUQmisipwBycUXhNhArsIvzTv3/GLa98ZfObGGPqdMzGdhHxADOB03Aa298H/qGqVfWe2EpZY3vw9heVc//89Tz7eS4+r4crTurD5Sf1IjE2mM5+xphIUl9je2OGkT8RuFBVr2mO4FqaJZKGy91dyL3/WsO7X39PRkoc/zWpH+cO72bjdRkTRZo8jLyIDBWRe93pcf8HWNOM8ZlWLqtjEo9cPIJ/XjmOzNQEfv3yV/zogU/4ZP2ucIdmjGkF6kwkIpItIreLyGrgIZx5SERVT1HVB1ssQtNqjMpK4/Wrx/PghcMoKK3gkscXM+PJxazbcTDcoRljwqjOqi0RqQI+AS5T1Q1u2Xeq2rsF42t2VrXVPErKK3lmYS4PfriBwtIKzh/Vg/84vS/p/vhwh2aMCYHGVm2dC3wPLBCRf4jIRJzGdmOI93mZeVIfPr7pFKaNy+KfS7cw4U8fcf+89RSUVoQ7PGNMCwqm11YScA5wIXAq8DTwmqq+H/LoQsDuSEJj4+5C7nl3Ne+t2kG7RB+X/6A308dnkRxnPbyMiQTN1mtLRNKAqcD5qnpqM8XXoiyRhNaKLfu4f946FqzdZQnFmAjSrN1/2zpLJC3DEooxkcUSSQBLJC3LEooxkcESSQBLJOFhCcWYts0SSQBLJOFVW0K5eExPUhN94Q7NGFMPSyQBLJG0DoEJJcHn5afDuzJjfBZ9M/zhDs0YUwtLJAEskbQuX2/dz9P/zuWNL7dRVlHFicd1ZMb4LE7pn25jeRnTilgiCWCJpHXaU1DKC0u28OzCTXx/oIQeaYlMG9eTqSO7k5pg1V7GhJslkgCWSFq38soq3l+1g6f+vZEluXtJjPVy7vBuTB/fk+PSrdrLmHCxRBLAEknb8fXW/Tz171zeXLGNssoqftC3I5eekMXJ2VbtZUxLs0QSwBJJ27O7oJQXFm/m2c83seNAKR2SYjl9QAaTB2Uyvk8H4mK84Q7RmIhniSSAJZK2q7yyinnf7GDu19+zYM1OCkor8MfFcEr/dKYMyuTk7E4k2XMpxoREfYmkxf/XiUh34BkgE6gCHlXV+91xvF4EsoBc4DxV3euecytwGVAJXK+q77nlI4CngARgLnCDRltmjCI+r4cf5nTmhzmdKa2o5N8b9vCvr7/ng9U7ePPLbcTFeDgpuxNTBmYy8fh02iXGhjtkY6JCi9+RiEhnoLOqLhcRP7AMZ3ThGUC+qt4jIrcA7VX1ZhEZAMwBRgNdgHlAtqpWishi4Abgc5xE8oCqvlvf59sdSeSpqKxiSe5e3lv1Pe+t+p7t+0vweoRxvTsweVAmZw3pYj2/jGmiVl21JSJv4MzA+BAwQVW3u8nmI1Xt596NoKp/cI9/D7gT565lgar2d8svdM+/or7Ps0QS2VSVr/L2869V3/Pe19/z3e5C+mX4eemKcfb0vDFN0OQ520NFRLKAYcAiIENVtwO463T3sK7AloDT8tyyru72keW1fc5MEVkqIkt37bJ5xiOZiDCkeztuntKf+f91Mk9eOoqNuwu57OklFJdVhjs8YyJS2BKJiCQDrwC/UtUD9R1aS5nWU350oeqjqjpSVUd26tSp4cGaNklEOKVfOn87fyjLNu/lmueXU15ZFe6wjIk4YUkkIuLDSSLPqeqrbvEOt0qruh1lp1ueB3QPOL0bsM0t71ZLuTGH+dHgzvzP2YP4cM1Obn7lK6qqrD+GMc2pxROJiAjwOLBaVf8a8NKbwHR3ezrwRkD5BSISJyK9gL7AYrf666CIjHXfc1rAOcYc5uKxPfnP07N5dflWfj93NeFuGzQmkoSj0/0JwCXAShFZ4Zb9N3AP8JKIXAZsxpnSF1VdJSIvAd8AFcA1qlpd2X0Vh7r/vusuxtTqulOPY09BKY99upGO/jiuPLlPuEMyJiK0eCJR1U+pvX0DYGId59wN3F1L+VJgUPNFZyKZiHDHjweSX1TOPe+uIS0xlvNGdT/2icaYetljwCaqeDzCX6YOYV9RGbe8+hWpiT4mD8wMd1jGtGlh7f5rTDjExniYdfEIcrq147o5X/D5d3vCHZIxbZolEhOVkuJieHLGKLq3T+Dyp5eyatv+cIdkTJtliSRYFaWwa224ozDNKC0plmcvG0NyfAzTn1jCpj2F4Q7JmDbJEkmwPv0bzDrRWVfZE9KRoku7BJ69bDQVVVVc8vhidh4oCXdIxrQ5lkiCNfIyyJ4M8+6EJybD7vXhjsg0k+PS/Tw5YxS7C0qZ/uQS9heXhzskY9oUSyTBSu4E5z0L5z7uJJFZJ8LCh6HKhtyIBMN6tGfWxSPYsPMg5zz8GU99tpEDJZZQjAlG2Ef/bWnNMvrvwe/hrRtg3b+gx3g452FI6908AZqw+mjtTv76wTq+yttPgs/LWUO6cPHYnuR0Sw13aMaEVaseRr6lNdsw8qrw5Rx49xaoKofT73Kqvzx2kxcJvsrbx/OLNvPGim0Ul1cyuFsqF4/pyY+HdCEh1qb2NdHHEkmAZp+PZP9WePNa+PZD6HUynP0QtOvRfO9vwmp/cTmvf7GV2Z9vYv3OAvzxMZw7vBsXjelB3wx/uMMzpsVYIgkQkomtVGHZU/D+bYDA5Lth+DSQukaCMW2NqrIkdy+zP9/Eu19vp7xSGd0rjYvH9mTywAziYuwuxUQ2SyQBQjpD4t5N8MY1kPsJHHca/PgBSK11ri3Thu0uKOXlZXk8v2gzm/OLSIr1cnznFAZ0SWFglxQGdE6lb0Yy8T5LLiZyWCIJEPKpdquqYMljMO8OEA/0GAudh0KXYc6S0sXuVCJEVZXy8fpdfLhmJ6u3H+CbbQcodGdhjPEIx6UnM8BNMNXrdomxYY7amMaxRBKgxeZs3/MtfHYfbF0OO1dD9cj3SenQZeihxNJ5KKR0Dn08JuSqqpTN+UV84yaVVdv28832A+w4UFpzTNd2CRzf2blzGdQ1lUFdU8hMiUfsjwvTylkiCdBiiSRQeTF8/zVs+wK2r3DWu9aAus+gJGceSix9ToWuI6z3VwTZXVBac8eyyk0w3+0upPq/XlpSLAO7pDCwi5NYBnZJpWdaIh6PJRfTelgiCRCWRFKbssJDyaU6wexaCyj4O0O/M+D4M6HniRBj1SGRprC0gjXfO4nl6637WbXtAOt2HKS80vn/mBwXw4DOKQx0E8vxnf0cl55sjfombCyRBGg1iaQ2xXth/Qew+i3YMA/KiyAu1Rma5fgznQb82KRwR2lCpLSikvU7Cli1bT9fbz1UNVZS7ty5ej1C745J9O+cQv9MP/0z/fTL9NO1XYJVjZmQs0QSoFUnkkDlxfDtAljzDqydC8X5EBPvVH31/xFk/xCSOoQ7ShNilVXKxt0FrN5+kLXfH2TN9wdY8/1B8vYW1xzjj4+hX4af/p399M90kkzvTsm0T/RZgjHNxhJJgDaTSAJVVsDmhbDmbSex7N/i9AjreQJ0Hw1pfZwhWjr0gaRO1issChwsKWfdjoNHJZiDJRU1x/jjY+jZIZGeaUnOukMiPTs42xn+eGuDMQ1iiSRAm0wkgVRh+5dOUln7rtNoX3Xoy4NYP3To7SSWtD5OcqneTupoSSaCqSrb9pew9vsDbNxdxOY9heTuKWJzfhFb8ouoqDr0fz0uxkOPtEOJpTrJZHVIpEu7BHxe6+xhDmeJJECbTyRHqiyHfZsh/ztn2fMt5H/rrPdtPtTtGCAuxblj8caC1+eu69r2OUtsMqR2h3bdnXVqN0hobwmpjamorGL7/hJy9xSyaU8Rm2rWRWzKL6xphwGnLaZb+wR6pCWSVZNonHWPtER70DJKWSIJEHGJpD7VSSYwuRTnQ2WZ81plecB24Dpgu2Q/VJYe/r7VySW1m5tgukFqD2fbnwneOCcJeWIOJSZPjCWfVkpV2XWwlNzABJPvbOfuLuRAQHUZQGZKPN3TEkj3x5OeEke6P56MlDgyUuJJ98eRnhJPSnyMtc9EGEskAaIqkTQHVSjcDfs3w74tsD/PaaPZt8VZ79/i9DYLhicGPL6AJBPrdG1OSHOq3ZI6QWIHZ12z39Hd7mg91sJkX1HZYUkmd08h2/YVs/NgKTsPlFJQWnHUOfE+T02CSffH0zE5lpQEH/74GPzxPlLiq7er92NISfARF+OJ3ARUWeH0xKwocdblxe66xNmuKnf/8IpzOtbExLrbsc5+4Hb1H2ZVVQHvVeisy4rcMncJ3O99CnQe3Kjw60skMU36wZjIJ+JM6pXcyXlQsjalBYcSTMEO946mwvmPcdh2ubuucMqryqGiFIryoWi38xxN4S7nP1ptfIlOYvE28J9tQhq0z4K0Xs66vbv2d7YHP4PQLsHH0AwfQ9t5oZtAmUKFByQJJJni8iryiyvZU1jGnsJy9hZVsLuwjD1FxewuKGP31gq2FpUgZQUkUUISxfilmCRKSKaY5OptKcYvJbTzlJDkKSPGK8R4vMR4PcTEeInxevHFOPu+GC++mBi8Ik7HE/E4X7C+eIhJAF+Cs+1LdMsTj9hPcKbMrvliLz56fWRZZZlzjlY6X+BaGbBfS3lV+aH3qU4UzUacpFNZ1rDTzvhzoxNJfSyRmKaLS4b0/s7SVKrOw5pFu507ocLdTnKp3i/ac3jngmDer3AX5C2GVa8eGk0AnL/w2vc8PLmk9XLuhDxe9w7KXcRz+L4n5tAx1V9kIoDUvg78K1sVygqcasOSA1B6wFmX7IfS/QHbbnlZgfM5MfHuEnfstVYFJO5aqjKPLC8vgtKDzlJW4PxxUL1dVnD4z+0ICUBXd6lXHc/VVnp8lHuTKPMmUeJJoFgSKNJUiiurqKiopLy0korKCjyUI4BHnFgExeeBWA/EeSHFV0VqTAWxlCHVf+lXFNf+ofUSJ9EEJqCYBPdO2gviPfS7j4k7tF+z9riv+9yEluiuE45438Ay9/0ryw8lrYpSp1q5wl2qy6rLK8sD3iPRWWITA947yVnXlLnlIWCJxLQuIk5iikt2vtibU3Wb0d5cd9norPNzYdO/nS/MkHITiipwjCpljw/iUyA+1WmTqqp0vmAqSg9fN/av3OqqRY/PucPzJTk/89hkiG/ntHvF+iHOf6g8zt2PTXaqWBQ3waiz1irn2morE3E6e8S6v9s4v/v+yXhj4vAC8UBKHeGWVVSxp7CU3QfL2FVQ4q5L2XWwlF0FpeTtLWZl3j6qFDr545jYP51T+6dz4nEdSPRUHHGH4SYZjzfgiz1g7Y219rwGskRioofX53SH7tDn6NdUnSq2vRudNp+qSufOp2apZ18rj/gCxV3roXXNa+r8xRrndxJFnJss4lMDtlOcL7VgvsyqKgOSS8mhJCNeJ0FU98bzHLHdxqr0YmM8dE5NoHNqAlD7tMd7C8v4aN1O5q3eyTtfbeeFJVuIi/Ewvk8HJh6fwcTj0+ncITR/kUc7a2w3xkScsooqluTmM2/1Duav3snm/CIABnZJYWL/dCYen8GALin2vEwDWK+tAJZIjIkuqsq3uwqYt3on81fvYNmmvVSp87xM59R4urdPpHtagrs+tN3JHxe5PcgawXptGWOilohwXLqf49L9XHlyH/ILy/hk/S7W7yhgy17nqf8Fa3ex6+Dhz0vFxXicxNI+ge5piXRIiiMx1ktCrJcEn/eI7RgSYt0yn1Me0V2Zj2CJxBgTVdKSYjl76NF9zErKK8nbW8SW/OKaYWW2uPtLN+09bByzYHgEkmJjSIzz1qwTY2NIivWSGOeuY2NICihPioupWZLd8uS4GBLd11prcrJEYowxQLzPW3PnUpuKyiqKyyspLqukqKyS4nJ3XbNdccRrFRSVVVJUWkmhu11YWsHugjIK84tqygtLK6gKsoUhxiMkxnpJjoshPtYLCpWqVFYpVVVas129VKkzgnSlOq/fdfYgfj6mRzP+1Ny4mv0dW5iITAHuB7zAY6p6T5hDMsZEoBivB7/Xgz/e16zvq6qUVlRRWOokm4LSCorKKigoraSotMLdd8oDjykuq0TEaevxijhrj+AJ2PeI4PVQUzagS10drJumTScSEfECDwOnA3nAEhF5U1W/CW9kxhgTHBEh3ucl3uelrc4w1Nb7vo0GNqjqd6paBrwAnB3mmIwxJqq09UTSFdgSsJ9HLSM1iMhMEVkqIkt37drVYsEZY0w0aOuJpLbuC0c1W6nqo6o6UlVHdurUqQXCMsaY6NHWE0ke0D1gvxuwLUyxGGNMVGrriWQJ0FdEeolILHAB8GaYYzLGmKjSpnttqWqFiFwLvIfT/fcJVV0V5rCMMSaqtOlEAqCqc4G54Y7DGGOiVVuv2jLGGBNmUTf6r4jsAja5ux2B3WEMJxzsmqODXXPka+nr7amqtXZ7jbpEEkhEltY1LHKksmuODnbNka81Xa9VbRljjGkSSyTGGGOaJNoTyaPhDiAM7Jqjg11z5Gs11xvVbSTGGGOaLtrvSIwxxjSRJRJjjDFNErWJRESmiMhaEdkgIreEO56WICK5IrJSRFaIyNJwxxMKIvKEiOwUka8DytJE5AMRWe+u24czxuZUx/XeKSJb3d/zChE5I5wxNjcR6S4iC0RktYisEpEb3PJI/j3Xdc2t4ncdlW0k7syK6wiYWRG4MNJnVhSRXGCkqkbsQ1sichJQADyjqoPcsj8C+ap6j/tHQ3tVvTmccTaXOq73TqBAVf8czthCRUQ6A51VdbmI+IFlwDnADCL391zXNZ9HK/hdR+sdic2sGKFU9WMg/4jis4Gn3e2ncf4DRoQ6rjeiqep2VV3ubh8EVuNMaBfJv+e6rrlViNZEEtTMihFIgfdFZJmIzAx3MC0oQ1W3g/MfEkgPczwt4VoR+cqt+oqYKp4jiUgWMAxYRJT8no+4ZmgFv+toTSRBzawYgU5Q1eHAD4Fr3GoRE3keAfoAQ4HtwF/CGk2IiEgy8ArwK1U9EO54WkIt19wqftfRmkiicmZFVd3mrncCr+FU8UWDHW4dc3Vd884wxxNSqrpDVStVtQr4BxH4exYRH84X6nOq+qpbHNG/59quubX8rqM1kUTdzIoikuQ20iEiScAk4Ov6z4oYbwLT3e3pwBthjCXkqr9MXT8hwn7PIiLA48BqVf1rwEsR+3uu65pby+86KnttAbjd5O7j0MyKd4c3otASkd44dyHgTGj2fCRes4jMASbgDLG9A7gDeB14CegBbAamqmpENFDXcb0TcKo6FMgFrqhuO4gEInIi8AmwEqhyi/8bp80gUn/PdV3zhbSC33XUJhJjjDHNI1qrtowxxjQTSyTGGGOaxBKJMcaYJrFEYowxpkkskRhjjGkSSyQmYomIishfAvZvdAc0bI73fkpEftYc73WMz5nqjvi64IjyLBEpDhj1dYWITGvGz50gIm831/uZyBYT7gCMCaFS4Kci8ofWNOKxiHhVtTLIwy8DrlbVBbW89q2qDm2+yIxpHLsjMZGsAmde6/848oUj7yhEpMBdTxCR/xORl0RknYjcIyIXichidy6XPgFvc5qIfOIed6Z7vldE/iQiS9yB9K4IeN8FIvI8zkNlR8Zzofv+X4vIvW7Z7cCJwCwR+VOwFy0iBSLyFxFZLiLzRaSTWz5URD5343qteoA/ETlOROaJyJfuOdXXmCwiL4vIGhF5zn26Gvdn8o37PhE5VL1pIFW1xZaIXHDm6UjBeeI3FbgRuNN97SngZ4HHuusJwD6gMxAHbAV+6752A3BfwPn/wvljrC/O+G3xwEzgNveYOGAp0Mt930KgVy1xdsF5ErsTTi3Bh8A57msf4cwhc+Q5WUAxsCJg+YH7mgIXudu3Aw+5218BJ7vbdwVcyyLgJ+52PJDoxrsfZxw6D7AQJ6mlAWs59DBzu3D/nm0J/2J3JCaiqTNC6jPA9Q04bYk68z+UAt8C77vlK3G+wKu9pKpVqroe+A7ojzOG2TQRWYHzBd0BJ9EALFbVjbV83ijgI1XdpaoVwHNAMCMzf6uqQwOWT9zyKuBFd3s2cKKIpOJ86f+fW/40cJI7/lpXVX0NQFVLVLUoIN48dQYEXOFe+wGgBHhMRH4KVB9ropglEhMN7sNpa0gKKKvA/ffvVtnEBrxWGrBdFbBfxeHtikeOL6Q4UxRcF/Dl3ktVqxNRYR3x1TatQXOqbxyk+j478OdQCcS4iW40zii05+DclZkoZ4nERDx1Bu57CSeZVMsFRrjbZwO+Rrz1VBHxuG0KvXGqfN4DrnKH/EZEst3RluuzCDhZRDqKMw30hcD/HeOc+niA6vafnwOfqup+YK+I/MAtvwT4P/eOLU9EznHjjRORxLre2J0PI1VV5wK/whkw0EQ567VlosVfgGsD9v8BvCEii4H51H23UJ+1OF/4GcCVqloiIo/hVAEtd+90dnGMKV9VdbuI3AoswLlDmKuqwQyB3setQqv2hKo+gHMtA0VkGU47x/nu69NxGu4TcariLnXLLwH+V0TuAsqBqfV8ph/n5xbvxnpURwYTfWz0X2MijIgUqGpyuOMw0cOqtowxxjSJ3ZEYY4xpErsjMcYY0ySWSIwxxjSJJRJjjDFNYonEGGNMk1giMcYY0yT/H6Gp45oS/DYhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i+1 for i in range(num_epochs)]\n",
    "plt.plot(x, train_loss, label='Accumulated Training Loss')\n",
    "plt.plot(x, test_loss, label='Accumulated Testing Loss')\n",
    "\n",
    "# add axis labels and a title\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accumulated Loss')\n",
    "plt.title('Loss')\n",
    "\n",
    "# add a legend to distinguish the two lines\n",
    "plt.legend()\n",
    "\n",
    "# display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
